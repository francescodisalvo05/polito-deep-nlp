{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_05_Automatic_Text_Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francescodisalvo05/polito-deep-nlp/blob/main/Labs/Lab_05_Automatic_Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23KZw7Xd5XhK"
      },
      "source": [
        "#**Deep Natural Language Processing @ PoliTO**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Teaching Assistant:** Moreno La Quatra\n",
        "\n",
        "**Practice 5:** Automatic Text Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlb9Te9I5exv"
      },
      "source": [
        "## Extractive Text Summarization\n",
        "\n",
        "Content is extracted from the original data, but the extracted content is not modified in any way.\n",
        "\n",
        "![](https://images.deepai.org/machine-learning-models/8f66b1eb608e4eb681b2ec0c0631385c/summarization.jpg)\n",
        "\n",
        "For this part of the practice we will use the BBC News Summary dataset available in [Kaggle](https://www.kaggle.com/pariza/bbc-news-summary)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiCTbAwGA6RK"
      },
      "source": [
        "%%capture\n",
        "! wget https://github.com/MorenoLaQuatra/DeepNLP/raw/main/practices/P5/bbc_news.zip\n",
        "! unzip bbc_news.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoJgwbjDFCAq"
      },
      "source": [
        "### **Question 1: split data collection**\n",
        "\n",
        "Read the data collection and split it into train/test/eval. Data are provided with different classes (e.g., business, sport, tech...), be sure to select 10% of data for testing **for each class**.\n",
        "\n",
        "**Note 1:** Some files can report UnicodeError, feel free to ignore it (`errors` parameter)\n",
        "\n",
        "**Note 2:** you can fix encoding after file reading by using [ftfy](https://pypi.org/project/ftfy/) library "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFw-VeeLJCS7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0cd5b9-c61f-4899-c210-e263cd6059dd"
      },
      "source": [
        "!pip install ftfy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=7d23267db9d4a015206d37c54f4b46e582db2f1c9bb74cdfe85d3867ba97919a\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r_evLR5FBq4"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWGRHPMJucXY"
      },
      "source": [
        "import os \n",
        "import pandas as pd\n",
        "import ftfy\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2cCtNPRqr7R"
      },
      "source": [
        "classes = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
        "path = '/content/BBC News Summary/News Articles/'\n",
        "\n",
        "labels = []\n",
        "articles = []\n",
        "\n",
        "for c in classes:\n",
        "\n",
        "  files = os.listdir(path + c + \"/\")\n",
        "\n",
        "  for text in files:\n",
        "\n",
        "    with open(path + c + \"/\" + text, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "      curr_data = f.readlines()\n",
        "\n",
        "      # clean rows\n",
        "\n",
        "      phrases = []\n",
        "\n",
        "      for line in curr_data:\n",
        "        if line != \"\\n\": # remove \\n rows\n",
        "          curr_line = line.replace(\"\\n\",\"\") # remove final \\n\n",
        "          phrases.append(ftfy.fix_text(curr_line)) # fix encoding\n",
        "\n",
        "      articles.append(' '.join(phrases))\n",
        "      labels.append(c)\n",
        "\n",
        "      f.close()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppDq-7Tdt9Wh",
        "outputId": "47f9997a-8f8f-46a3-c9d6-25256c9a37b0"
      },
      "source": [
        "Counter(labels) # they're more or less balanced"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'business': 510,\n",
              "         'entertainment': 386,\n",
              "         'politics': 417,\n",
              "         'sport': 511,\n",
              "         'tech': 401})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPG-hYCuuLaB"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(articles, labels, test_size=0.1, stratify=labels)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0KPIrR3v0qf",
        "outputId": "0f96693b-98a1-41d1-c0b2-d82874e18d54"
      },
      "source": [
        "Counter(y_train), Counter(y_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Counter({'business': 459,\n",
              "          'entertainment': 347,\n",
              "          'politics': 375,\n",
              "          'sport': 460,\n",
              "          'tech': 361}),\n",
              " Counter({'business': 51,\n",
              "          'entertainment': 39,\n",
              "          'politics': 42,\n",
              "          'sport': 51,\n",
              "          'tech': 40}))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "j_Fp3Gn7RX0E",
        "outputId": "975d9161-eafb-43dd-afb8-ba78a762b313"
      },
      "source": [
        "X_test[0]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Profile: David Miliband David Miliband's rapid rise through the ranks of government continues with his promotion to Cabinet Office minister. Elected in a safe Labour seat in 2001 his previous job was school standards minister - a role he won in May 2002. Prior to the last election he was a key figure in New Labour as the head of the Downing Street policy unit where he was a key member of the manifesto writing team. Seen as one of the more intellectual figures in the government, he was also working for Tony Blair in his policy unit when he was leader of the opposition. A brief glance at Mr Miliband's family background reveals an impressive socialist pedigree in the form of his father Ralph, who died in 1994. He was an eminent and influential leftwing academic. And while David Miliband is seen as a key Blair lieutenant his brother Ed is a special advisor to Chancellor Gordon Brown. Prior to working for Mr Blair, David Miliband spent time at the left-leaning Institute for Public Policy Research. He then became secretary of the Commission on Social Justice. The 39-year-old was educated at Haverstock Comprehensive before going on to Oxford to study politics, philosophy and economics. He also took an MSc in political science from the Massachusetts Institute of Technology.\""
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTHNVAqn1Pfg"
      },
      "source": [
        "### **Question 2: Unsupervised Text Summarization (TextRank)**\n",
        "\n",
        "[TextRank](https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf) is an unsupervised text summarization approach that relies on graph modelling. Implement a `TextrankSummarizer` class that expose the `summarize(sentences, N)` function to get the `N` most relevant sentences from a list (`sentences`). \n",
        "\n",
        "The main steps are reported here:\n",
        "\n",
        "1. Each sentence is a node in a graph (undirected)\n",
        "2. A pair of sentence is connected with an edge whose weight is computed according to the number of common words (see Note 1).\n",
        "3. Pagerank is used to compute a relevance score for each node in the graph (for each sentence in the list)\n",
        "4. The `summarize` function return the summary concatenating the `N`  most relevant sentences (according to the score computed at step 3).\n",
        "\n",
        "**Note 1:** An example of the similarity function that can be used to compute graph weights is repoted below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDzCPn0E41sJ"
      },
      "source": [
        "import math\n",
        "\n",
        "def compute_similarity(tokens_sent_1, tokens_sent_2):\n",
        "\n",
        "    n_common_words = len(set(tokens_sent_1) & set(tokens_sent_2))\n",
        "\n",
        "    log_s1 = math.log10(len(tokens_sent_1))\n",
        "    log_s2 = math.log10(len(tokens_sent_2))\n",
        "\n",
        "    if log_s1 + log_s2 == 0:\n",
        "        return 0\n",
        "\n",
        "    return n_common_words / (log_s1 + log_s2)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPD6t1G1mWKG"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1sxerzWxiDv"
      },
      "source": [
        "import networkx as nx\n",
        "\n",
        "class TextrankSummarizer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.nodes = set()\n",
        "        self.edges = []\n",
        "        self.graph = nx.DiGraph()\n",
        "\n",
        "   \n",
        "    def summarize(self, sentences, N=2):\n",
        "\n",
        "      len_sentences = len(sentences)\n",
        "\n",
        "      for i in range(len_sentences):\n",
        "        for j in range(i,len_sentences):\n",
        "          \n",
        "          self.nodes.add(sentences[i])\n",
        "          self.nodes.add(sentences[j])\n",
        "\n",
        "          # add weighted edges to the graph\n",
        "          weight = compute_similarity(sentences[i], sentences[j])\n",
        "          self.edges.append((sentences[i], sentences[j], weight))\n",
        "          self.edges.append((sentences[j], sentences[i], weight))\n",
        "\n",
        "      # page rank\n",
        "      self.graph.add_nodes_from(list(self.nodes))\n",
        "      self.graph.add_weighted_edges_from(self.edges)\n",
        "\n",
        "      p = nx.pagerank(self.graph, max_iter=100)\n",
        "\n",
        "      # sort the results in descending order and take the top N\n",
        "      ordered_scores = sorted(list(p.items()), key=lambda x : -x[1])\n",
        "      top_N_tuple = sorted(list(p.items()), key=lambda x : -x[1])[:N]\n",
        "      top_N = [t[0] for t in top_N_tuple]\n",
        "\n",
        "      return top_N"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wYBaG7g7Jfo"
      },
      "source": [
        "### **Question 3: Unsupervised Text Summarization (TextRank + TF-IDF)**\n",
        "\n",
        "Implement a `TextrankTFIDFSummarizer` class that expose the `summarize(sentences, N)` function to get the `N` most relevant sentences from a list (`sentences`). \n",
        "\n",
        "Implement the class similarly to Q2. This version uses a different similarity function to weigh edges connecting sentences. It uses [TF-IDF vectorization](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) and [cosine similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) to compute sentence-to-sentence similarity.\n",
        "\n",
        "- Compute TF-IDF vectors for each sentence\n",
        "- Compute edges' weights using the cosine similarity between TF-IDF vector representations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uX1XCEVmarN"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxhVLN7ZNk-4"
      },
      "source": [
        "import networkx as nx\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxIxo2cYNiRG"
      },
      "source": [
        "def compute_similarity_tfidf(tokens_sent_1, tokens_sent_2):\n",
        "        \n",
        "  vectorizer = TfidfVectorizer()\n",
        "\n",
        "  tfidf_1 = vectorizer.fit_transform([tokens_sent_1])\n",
        "\n",
        "  # do only transform for having the same shape\n",
        "  tfidf_2 = vectorizer.transform([tokens_sent_2])\n",
        "\n",
        "  return cosine_similarity(tfidf_1,tfidf_2)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18xm5SUuAS_v"
      },
      "source": [
        "class TextrankTFIDFSummarizer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.nodes = set()\n",
        "        self.edges = []\n",
        "        self.graph = nx.DiGraph()\n",
        "\n",
        "   \n",
        "    def summarize(self, sentences, N=2):\n",
        "\n",
        "      len_sentences = len(sentences)\n",
        "\n",
        "      for i in range(len_sentences):\n",
        "        for j in range(len_sentences):\n",
        "\n",
        "          if i == j:\n",
        "            continue\n",
        "\n",
        "          self.nodes.add(sentences[i])\n",
        "          self.nodes.add(sentences[j])\n",
        "\n",
        "          # add weighted edges to the graph\n",
        "          weight = compute_similarity_tfidf(sentences[i], sentences[j])\n",
        "          self.edges.append((sentences[i], sentences[j], weight))\n",
        "\n",
        "      # page rank\n",
        "      self.graph.add_nodes_from(list(self.nodes))\n",
        "      self.graph.add_weighted_edges_from(self.edges)\n",
        "\n",
        "      p = nx.pagerank(self.graph, max_iter=100)\n",
        "\n",
        "      # sort the results in descending order and take the top N\n",
        "      ordered_scores = sorted(list(p.items()), key=lambda x : -x[1])\n",
        "      top_N_tuple = sorted(list(p.items()), key=lambda x : -x[1])[:N]\n",
        "      top_N = [t[0] for t in top_N_tuple]\n",
        "\n",
        "      return top_N"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVRrBOKxCPyR"
      },
      "source": [
        "### **Question 4: Unsupervised Text Summarization (Pretrained BERT)**\n",
        "\n",
        "Both Textrank and Lexrank relies on syntactic scores to compute sentence similarity. \n",
        "Use Sentence-Transformer library to encode sentences into semantic-aware vectors and compute semantic similarity to interconnect sentences (e.g., use cosine similarity of bert encodings). Implement `BERTSummarizer` class similarly to Q2 and Q3.\n",
        "\n",
        "Note 1: use `sentence-transformers` library to obtain sentence embeddings (https://www.sbert.net/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzCUdyrkmchL"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYPJKTM1CcEE"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9E__nDECPHp"
      },
      "source": [
        "import networkx as nx\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class  BERTSummarizer:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.nodes = set()\n",
        "        self.edges = []\n",
        "        self.graph = nx.DiGraph()\n",
        "        self.bert = SentenceTransformer(\"stsb-mpnet-base-v2\")\n",
        "\n",
        "    \n",
        "    def compute_similarity(self, tokens_sent_1, tokens_sent_2):\n",
        "        \n",
        "        tokens_enc_1 = self.bert.encode(tokens_sent_1)\n",
        "        tokens_enc_2 = self.bert.encode(tokens_sent_2)\n",
        "        \n",
        "        return cosine_similarity(tokens_enc_1.reshape(-1,1),tokens_enc_2.reshape(-1,1))\n",
        "\n",
        "   \n",
        "    def summarize(self, sentences, N=2):\n",
        "\n",
        "      len_sentences = len(sentences)\n",
        "\n",
        "      for i in range(len_sentences):\n",
        "        for j in range(i,len_sentences):\n",
        "\n",
        "          self.nodes.add(sentences[i])\n",
        "          self.nodes.add(sentences[j])\n",
        "\n",
        "          # add weighted edges to the graph\n",
        "          weight = self.compute_similarity(sentences[i], sentences[j])\n",
        "          self.edges.append((sentences[i], sentences[j], weight))\n",
        "          self.edges.append((sentences[j], sentences[i], weight))\n",
        "\n",
        "      # page rank\n",
        "      self.graph.add_nodes_from(list(self.nodes))\n",
        "      self.graph.add_weighted_edges_from(self.edges)\n",
        "\n",
        "      p = nx.pagerank(self.graph, max_iter=100)\n",
        "\n",
        "      # sort the results in descending order and take the top N\n",
        "      ordered_scores = sorted(list(p.items()), key=lambda x : -x[1])\n",
        "      top_N_tuple = sorted(list(p.items()), key=lambda x : -x[1])[:N]\n",
        "      top_N = [t[0] for t in top_N_tuple]\n",
        "\n",
        "      return top_N"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmSnChfIFSKc"
      },
      "source": [
        "### **Question 5: ROUGE-based evaluation**\n",
        "\n",
        "Using only the **test set** obtained in Q1 compare the performance of the three summarizers implemented in Q2, Q3 and Q4. \n",
        "\n",
        "Report their results in terms of average precision, recall and F1-score for Rouge 2 metrics. Set the number of extracted sentences to 4 for all summarizers.\n",
        "\n",
        "**Which method obtain the best scores?**\n",
        "\n",
        "Note 1: You can use the python implementation of ROUGE available [here](https://pypi.org/project/rouge/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW42pxUXEhSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b820e49-b63c-4b2b-9aab-9abd12659a53"
      },
      "source": [
        "! pip install rouge"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dba9zCcZmfpd"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC2wwjKYNU6g"
      },
      "source": [
        "textrank = TextrankSummarizer()\n",
        "summary_text_rank = textrank.summarize(X_test,4)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfajDcikObG8"
      },
      "source": [
        "textrank_tfidf = TextrankTFIDFSummarizer()\n",
        "summary_tr_tfidf = textrank_tfidf.summarize(X_test,4)\n",
        "\n",
        "# -- row, column, and data arrays must be 1-D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRnz10BQOibr"
      },
      "source": [
        "textrank_bert = BERTSummarizer()\n",
        "summary_bert = textrank_bert.summarize(X_test,4)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTHHcu0IIxeH"
      },
      "source": [
        "## Abstractive Text Summarization\n",
        "\n",
        "Abstractive methods build an internal semantic representation of the original content, and then use this representation to create a summary that is closer to what a human might express. Abstraction may transform the extracted content by paraphrasing sections of the source document, to condense a text more strongly than extraction. Such transformation, however, is computationally much more challenging than extraction.\n",
        "\n",
        "![https://techcommunity.microsoft.com/t5/image/serverpage/image-id/180981i9EA877DDFF97D50D?v=v2](https://techcommunity.microsoft.com/t5/image/serverpage/image-id/180981i9EA877DDFF97D50D?v=v2)\n",
        "\n",
        "Also for this part of the practice we use the BBC News Summary dataset available in [Kaggle](https://www.kaggle.com/pariza/bbc-news-summary)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQbCIzgtKIkV"
      },
      "source": [
        "### **Question 6: BART (pretrained) seq2seq model**\n",
        "\n",
        "Exploit [BART](https://huggingface.co/facebook/bart-large-cnn) pretrained on CNN Daily Mail dataset to summarize the article in the BBC test set. Compute the obtained scores in terms of average precision, recall and F1-score for Rouge 2 metrics.\n",
        "\n",
        "Note 1: for generated summaries set the maximum length to 100 and the minimum length to your preferred value.\n",
        "\n",
        "Note 2: **to speed up computation**, you can use the distilled version of the BART model (e.g., `sshleifer/distilbart-cnn-12-6` available [here](https://huggingface.co/sshleifer/distilbart-cnn-12-6))\n",
        "\n",
        "Note 3: You can use the [summarization pipeline](https://huggingface.co/transformers/main_classes/pipelines.html#transformers.SummarizationPipeline). Explictly set truncation to True to avoid index errors (e.g. `summarizer(..., truncation=True)`)\n",
        "\n",
        "Note 4: Explictly set the device to use GPU acceleration (colab runtime should be also set to GPU) while creating the pipeline object (e.g., `pipeline(..., device=0)`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FXMx1i0mlnb"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puVi1x74FfGh"
      },
      "source": [
        "### **Question 7 (bonus): Finetuning seq2seq model**\n",
        "\n",
        "Exploit the BBC dataset to finetune BART-based model on the proposed dataset. Create a fine-tuning procedure using the article text as input and the ground-truth summary as output of the model.\n",
        "\n",
        "Exploit the [Datasets framework](https://huggingface.co/docs/datasets/) and [Trainer API](https://huggingface.co/transformers/training.html#fine-tuning-in-pytorch-with-the-trainer-api) for training and evaluating the model.\n",
        "\n",
        "Even in this case, evaluate the model using ROUGE-2 precision, recall and f1-score. At this time, you may want to use [metrics python library](https://huggingface.co/metrics) to set the [`compute_metrics`](https://huggingface.co/transformers/main_classes/trainer.html#id1) parameter in Trainer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PELrns0Xo1r9"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}