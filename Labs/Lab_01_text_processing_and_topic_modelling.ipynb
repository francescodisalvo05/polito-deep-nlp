{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_01_text_processing_and_topic_modelling",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francescodisalvo05/polito-nlp/blob/main/Labs/Lab_01_text_processing_and_topic_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Yl_iXiRJHtC"
      },
      "source": [
        "## Import Everything"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_AatxmlJXwy",
        "outputId": "4e3bb017-ad10-42aa-f64a-25465f86a596"
      },
      "source": [
        "# install\n",
        "!pip install fastlangid\n",
        "!pip install iso639-lang\n",
        "!pip install langdetect\n",
        "!pip install langid"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastlangid in /usr/local/lib/python3.7/dist-packages (1.0.3)\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (from fastlangid) (0.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext->fastlangid) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext->fastlangid) (1.21.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext->fastlangid) (2.8.0)\n",
            "Requirement already satisfied: iso639-lang in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "Requirement already satisfied: langid in /usr/local/lib/python3.7/dist-packages (1.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from langid) (1.21.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3qrAEd5JFWh",
        "outputId": "a600cef6-abf1-45af-855b-99a7ce64d0be"
      },
      "source": [
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "from iso639 import Lang\n",
        "from langdetect import detect\n",
        "from fastlangid.langid import LID\n",
        "import langid\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel, LsiModel\n",
        "\n",
        "import pyLDAvis\n",
        "from pyLDAvis import gensim_models\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZIl1U-b7AzU"
      },
      "source": [
        "# **Deep Natural Language Processing @ PoliTO**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Teaching Assistant:** Moreno La Quatra\n",
        "\n",
        "**Practice 1:** Text processing and topic modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1vQPzjM9r8c"
      },
      "source": [
        "# **Text processing**\n",
        "---\n",
        "The text processing phase is a preliminary stage where the text to be manipulated is processed to be ready for subsequent analysis.\n",
        "\n",
        "Text processing usually entails several steps that could possibly include:\n",
        "- **Language Identification**: identifying the language of a given text.\n",
        "- **Tokenization**: splitting a given text in several sentences/words. \n",
        "- **Dependency tree parsing:** analyzing the depencies between words composing the text.\n",
        "- **Stemming/Lemmatization:** obtain the root form for each word in text.\n",
        "- **Stopword removal**: removing words that are si commonly used that they carry very little useful information.\n",
        "- **Part of Speech Tagging:** given a word, retrieve its part of speech (proper noun, common noun or verb).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2dHRmrPB22r"
      },
      "source": [
        "### Language Identification\n",
        "\n",
        "| Text                                                                                                                                | Language Code |\n",
        "|-------------------------------------------------------------------------------------------------------------------------------------|---------------|\n",
        "| The \"Deep Natural Language Processing\" course is offered during the first semester of the second year at Politecnico di Torino      | `EN`            |\n",
        "| Il corso \"Deep Natural Language Processing\" viene impartito al Politecnico di Torino durante il primo semestre del secondo anno.    | `IT`            |\n",
        "| Le cours \"Deep Natural Language Processing\" est enseigné au Politecnico di Torino pendant le premier semestre de la deuxième année. | `FR`            |\n",
        "\n",
        "**Language Identification** is a crucial prelimiary step because each language has its own characteristics. The knowledge of the main language associated to a given text could be beneficial for all subsequent steps in text processing pipeline.\n",
        "\n",
        "The data collection used in this first part of the practice is provided [here](https://github.com/MorenoLaQuatra/DeepNLP/blob/main/practices/P1/langid_dataset.csv) - [source: Kaggle](https://www.kaggle.com/martinkk5575/language-detection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ej_dfjm2srd"
      },
      "source": [
        "# Exercise 1:\n",
        "\n",
        "Benchmark different language-detection algorithm by computing the accuracy of each approach:\n",
        "- [FastText](https://pypi.org/project/fastlangid/)\n",
        "- [LangID](https://github.com/saffsd/langid.py)\n",
        "- [langdetect](https://pypi.org/project/langdetect/)\n",
        "\n",
        "**Hint:** language code conversion: [iso639-lang](https://pypi.org/project/iso639-lang/)\n",
        "\n",
        "For each method report:\n",
        "- Accuracy\n",
        "- Average time per example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ7xbkps3_mR"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P1/langid_dataset.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os33d8TN-cgb"
      },
      "source": [
        "Your code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-509xNcU0tcU"
      },
      "source": [
        "df = pd.read_csv('langid_dataset.csv')\n",
        "\n",
        "y = df.language\n",
        "X = df.Text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0qroZWgEY8P"
      },
      "source": [
        "### FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aagUoWslD64Q",
        "outputId": "c5064b68-9694-414e-e5cc-087fc10da165"
      },
      "source": [
        "%%time\n",
        "\n",
        "fastlangid = LID()\n",
        "\n",
        "results_FastText = fastlangid.predict(X)\n",
        "\n",
        "# there are several dialects for Chineese\n",
        "results_FastText = [\"zh\" if x[:2] == \"zh\" else x for x in results_FastText]\n",
        "results_name_FastText = [Lang(x).name for x in results_FastText]\n",
        "\n",
        "print(\"Accuracy for FastText : \", accuracy_score(y, results_name_FastText))\n",
        "print(\"---------------------------------\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for FastText :  0.9677272727272728\n",
            "---------------------------------\n",
            "CPU times: user 3.58 s, sys: 20.5 ms, total: 3.6 s\n",
            "Wall time: 3.61 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv-VTz5JKw06"
      },
      "source": [
        "### LangID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9eu5EpAKvYx",
        "outputId": "ddc9def0-93d7-4354-9262-28f2767e2790"
      },
      "source": [
        "%%time\n",
        "\n",
        "results_langid = [Lang(langid.classify(x)[0]).name for x in X]\n",
        "\n",
        "print(\"Accuracy for LangID : \", accuracy_score(y, results_langid))\n",
        "print(\"--------------------------------------\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for LangID :  0.9542727272727273\n",
            "--------------------------------------\n",
            "CPU times: user 1min 15s, sys: 53.6 s, total: 2min 9s\n",
            "Wall time: 1min 7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_4QgsMNEauF"
      },
      "source": [
        "### LangDetect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jufhQJSEGh_V",
        "outputId": "6f4d8864-ed03-4f72-bdfc-71ea1d435f80"
      },
      "source": [
        "%%time\n",
        "results_LangDetect = []\n",
        "\n",
        "# there are four rows that give the error \"no features in text\"\n",
        "# one is blank but the other three are Arabic\n",
        "# >> I will manually omit these ones\n",
        "\n",
        "errors_idxs = []\n",
        "y_cleaned = y.copy()\n",
        "\n",
        "for i,x in enumerate(X):\n",
        "\n",
        "    try:\n",
        "        language = detect(x)\n",
        "\n",
        "        if language.startswith(\"zh\"):\n",
        "          language = \"zh\"\n",
        "        \n",
        "        results_LangDetect.append(Lang(language).name)\n",
        "\n",
        "    except:\n",
        "        # drop this element from y\n",
        "        y_cleaned.drop(i,inplace=True)\n",
        "\n",
        "print(\"Accuracy for LangDetect : \", accuracy_score(y_cleaned, results_LangDetect))\n",
        "print(\"--------------------------------------\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for LangDetect :  0.8752557166886393\n",
            "--------------------------------------\n",
            "CPU times: user 2min 29s, sys: 1.61 s, total: 2min 30s\n",
            "Wall time: 2min 30s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIOgOZy1ENh2"
      },
      "source": [
        "# Exercise 2\n",
        "\n",
        "For English-written text, apply word-level tokenization. What is the average number of words per sentence?\n",
        "\n",
        "Implement word-tokenization using both [nltk](https://www.nltk.org/) and [spacy](https://spacy.io/). Report the results for both of them.\n",
        "\n",
        "For spaCy use the `en_core_web_sm` model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP1svZFuMYD8"
      },
      "source": [
        "### Filter English Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2iMunR6Q33R"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Ph9mCx00sQ"
      },
      "source": [
        "X_eng = df[df[\"language\"] == \"English\"][[\"Text\"]]\n",
        "\n",
        "X_eng[\"num_tokens_nltk\"] = df[\"Text\"].apply(lambda x : len(word_tokenize(x)))\n",
        "X_eng[\"num_tokens_spacy\"] = df[\"Text\"].apply(lambda x : len(nlp(x)))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Es7AAadESh6L",
        "outputId": "1792ba59-7f53-4af2-bd58-c9f41b706d61"
      },
      "source": [
        "X_eng.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>num_tokens_nltk</th>\n",
              "      <th>num_tokens_spacy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>in  johnson was awarded an american institute ...</td>\n",
              "      <td>28</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>bussy-saint-georges has built its identity on ...</td>\n",
              "      <td>40</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>minnesotas state parks are spread across the s...</td>\n",
              "      <td>132</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>nordahl road is a station served by north coun...</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>a talk by takis fotopoulos about the internati...</td>\n",
              "      <td>50</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Text  ...  num_tokens_spacy\n",
              "37  in  johnson was awarded an american institute ...  ...                30\n",
              "40  bussy-saint-georges has built its identity on ...  ...                50\n",
              "76  minnesotas state parks are spread across the s...  ...               144\n",
              "90  nordahl road is a station served by north coun...  ...                59\n",
              "97  a talk by takis fotopoulos about the internati...  ...                53\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PyW3iedRBJ_",
        "outputId": "24c56085-f128-4fe3-96d3-c6522cd61f6a"
      },
      "source": [
        "X_eng.mean(axis=0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "num_tokens_nltk     68.738\n",
              "num_tokens_spacy    72.334\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySnw80QnIf2p"
      },
      "source": [
        "# Exercise 3\n",
        "\n",
        "Use spacy to parse the dependency tree of a **randomly selected** sentence. You can both use English sentences or your native language (if supported in [spaCy](https://spacy.io/usage/models/)). Use [displaCy](https://explosion.ai/demos/displacy) to visualize the result in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "UihIP60fTb1k",
        "outputId": "25f92c28-192e-4a38-c600-34491a24464d"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "sentence = \"Hello, I am Francesco and I am studying at Politecnico!\"\n",
        "\n",
        "doc = nlp(sentence)\n",
        "displacy.render(doc, style=\"dep\", jupyter=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"fc6017c8ac7044a190b4818d57af5d88-0\" class=\"displacy\" width=\"1800\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Hello,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">INTJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">I</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">am</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Francesco</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">and</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">I</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">am</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">studying</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">at</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">Politecnico!</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fc6017c8ac7044a190b4818d57af5d88-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fc6017c8ac7044a190b4818d57af5d88-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">intj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fc6017c8ac7044a190b4818d57af5d88-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fc6017c8ac7044a190b4818d57af5d88-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fc6017c8ac7044a190b4818d57af5d88-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fc6017c8ac7044a190b4818d57af5d88-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fc6017c8ac7044a190b4818d57af5d88-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fc6017c8ac7044a190b4818d57af5d88-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fc6017c8ac7044a190b4818d57af5d88-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fc6017c8ac7044a190b4818d57af5d88-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fc6017c8ac7044a190b4818d57af5d88-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fc6017c8ac7044a190b4818d57af5d88-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fc6017c8ac7044a190b4818d57af5d88-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fc6017c8ac7044a190b4818d57af5d88-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1440.0,266.5 L1448.0,254.5 1432.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-fc6017c8ac7044a190b4818d57af5d88-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-fc6017c8ac7044a190b4818d57af5d88-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1615.0,266.5 L1623.0,254.5 1607.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "yC77QpYrUP2_",
        "outputId": "9f981ced-ab04-4a86-f34f-fd3a3d1a7530"
      },
      "source": [
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hello, I am \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Francesco\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and I am studying at \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Politecnico\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "!</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAO1E6adVMKW"
      },
      "source": [
        "# Exercise 4\n",
        "For the same sentence selected in the previous step apply all the following steps:\n",
        "1. Lemmatization: convert each word to its root form.\n",
        "2. Stopword removal: remove language-specific stopwords.\n",
        "3. Part of Speech Tagging: for each word in the sentence display its part-of-speech.\n",
        "\n",
        "For each step, print the resulting list on the console."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4-wJHnOZnwC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46687929-7c3d-43ab-9a62-c2e241b32719"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmatized_tokens = []\n",
        "cleaned_tokens = []\n",
        "\n",
        "stopwords_eng = stopwords.words('english')\n",
        "\n",
        "# change the noun for the lemmatization\n",
        "sentence = \"He is Francesco and he studies at Politecnico\"\n",
        "tokens = word_tokenize(sentence)\n",
        "\n",
        "# step 0 : print sentence\n",
        "print(f\"Step 0 : {sentence}\")\n",
        "\n",
        "# step 1 : Lemmatization\n",
        "for token in tokens:\n",
        "    \n",
        "    # lemmatization's result is a common sense word\n",
        "    # therefore we should apply it before the stopword removal\n",
        "\n",
        "    # lemmatization\n",
        "    lemmatized_tokens.append(lemmatizer.lemmatize(token))\n",
        "\n",
        "print(f\"Step 1 : {' '.join(lemmatized_tokens)}\")\n",
        "\n",
        "\n",
        "# step 2 : Stopwords removal\n",
        "for l_token in lemmatized_tokens:    \n",
        "    \n",
        "    if l_token not in stopwords_eng:\n",
        "      cleaned_tokens.append(l_token)\n",
        "\n",
        "print(f\"Step 2 : {' '.join(cleaned_tokens)}\")\n",
        "    \n",
        "# step 3 : POS tagging\n",
        "print(f\"Step 3 : {nltk.pos_tag(cleaned_tokens)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0 : He is Francesco and he studies at Politecnico\n",
            "Step 1 : He is Francesco and he study at Politecnico\n",
            "Step 2 : He Francesco study Politecnico\n",
            "Step 3 : [('He', 'PRP'), ('Francesco', 'NNP'), ('study', 'NN'), ('Politecnico', 'NNP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL4KXiBkZrta"
      },
      "source": [
        "# **Occurrence-based text representation - TF-IDF**\n",
        "\n",
        "---\n",
        "TF-IDF (term frequency-inverse document frequency) is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. It allows to create occurrence-based vector representation for each document.\n",
        "\n",
        "# Exercise 5\n",
        "Use TF-IDF to vectorize each sentence in the original data collection. You can choose your preferred implementation for TF-IDF vectorization. It is also available on [SciKit-Learn library](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7L162ayglUq"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_vec = vectorizer.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4NTwm6Qbpvx"
      },
      "source": [
        "# Exercise 6\n",
        "\n",
        "Build a supervised multi-class language detector using as features the vector obtained by TF-IDF representation. Use 80% of the data to train the language detector and 20% of the data for assessing its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1HT2roy1DQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1514ec6e-2095-4ea1-f8e4-0e587f354eb2"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_vec,y, test_size=0.2, stratify=y)\n",
        "\n",
        "model = LogisticRegression().fit(X_train,y_train)\n",
        "results = model.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test,results))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9518181818181818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AHlGUHuaqjW"
      },
      "source": [
        "# **Topic Modelling**\n",
        "\n",
        "Occurrence-based representations are high-dimensional, what is the dimension of the generated TF-IDF vector representation?\n",
        "Topic modelling focuses on caturing latent topics in large document corpora.\n",
        "\n",
        "The data collection used in this second part of the practice is provided [here](https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P1/CovidFake_filtered.csv) - [source: Zenodo](https://zenodo.org/record/4282522#.YVdCXcbOOpd)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZbbPhC6cAO8"
      },
      "source": [
        "# Exercise 7\n",
        "\n",
        "Latent Semantic Indexing (LSI) models underlying concepts by using SVD (Singular Value Decomposition).\n",
        "\n",
        "Use [gensim](https://radimrehurek.com/gensim/) library to:\n",
        "1. Create a corpus composed of the headlines contained in the data collection.\n",
        "2. Generate a [dictionary](https://radimrehurek.com/gensim/corpora/dictionary.html) to create a word -> id mapping (required by LSI module).\n",
        "3. Using the dictionary, preprocess the corpus to obtain the representation required for LSI model training ([documentation here](https://radimrehurek.com/gensim/models/lsimodel.html)).\n",
        "4. Inspect the top-5 topics generated by the LSI model for the analysed corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwkHsT8oft_d"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P1/CovidFake_filtered.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPFhXH-Q6dW6"
      },
      "source": [
        "def preprocess_text(documents):\n",
        "  \"\"\"\n",
        "  :param df: (Series) documents to clean\n",
        "  :return: (Series) cleaned documents \n",
        "           - Lemmatization\n",
        "           - Stopwords \n",
        "  \"\"\"\n",
        "\n",
        "  # tokenizer that removes punctuation\n",
        "  tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  stopwords_eng = stopwords.words('english')\n",
        "\n",
        "  cleaned_docs = []\n",
        "\n",
        "  for curr_doc in documents:\n",
        "\n",
        "    # lowercase\n",
        "    curr_doc = curr_doc.lower()\n",
        "    # tokenize\n",
        "    curr_tokens = tokenizer.tokenize(curr_doc)\n",
        "    # lemmatized tokens\n",
        "    curr_lemmas = [lemmatizer.lemmatize(t) for t in curr_tokens]\n",
        "    # remove stopwords\n",
        "    cleaned_tokens = [t for t in curr_lemmas if not t in stopwords_eng]\n",
        "\n",
        "    cleaned_docs.append(cleaned_tokens)\n",
        "\n",
        "  return cleaned_docs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoJAZsw11Gih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c71c5c10-d11b-407c-e732-fc3ccf54255e"
      },
      "source": [
        "# step 0\n",
        "df_covid = pd.read_csv('CovidFake_filtered.csv').drop(columns=['Unnamed: 0'])\n",
        "\n",
        "# step 1\n",
        "headlines = df_covid.headlines\n",
        "headlines_cleaned = preprocess_text(headlines)\n",
        "\n",
        "# step 2\n",
        "dct = Dictionary(headlines_cleaned)  # initialize a Dictionary\n",
        "\n",
        "# step 3\n",
        "\n",
        "# generate a bag of word corpus\n",
        "corpus_bow = []\n",
        "for x in headlines_cleaned:\n",
        "  corpus_bow.append(dct.doc2bow(x))\n",
        "\n",
        "# show the first 10 tokens of the first document\n",
        "print(corpus_bow[0][10])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWw16_sH153w"
      },
      "source": [
        "# step 4\n",
        "lsi_model = LsiModel(corpus_bow, id2word=dct, num_topics=5)  \n",
        "result_lsi = lsi_model.print_topics(num_topics=5, num_words=5)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haNHAdeqiwQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3853a6c-d19f-4fdc-e1d4-17242efd0e20"
      },
      "source": [
        "# example of result\n",
        "result_lsi[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0,\n",
              " '0.608*\"covid\" + 0.600*\"19\" + 0.251*\"coronavirus\" + 0.153*\"ha\" + 0.138*\"claim\"')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jji1_KA8AD20",
        "outputId": "31f18a32-8626-402f-99e7-d835b9503616"
      },
      "source": [
        "def clean_print_result(result):\n",
        "  for res in result:\n",
        "    \n",
        "    # extract the most representative words for that topic\n",
        "    words = re.findall('[a-z]{1,}', res[1])\n",
        "    joined_words = ', '.join(words)\n",
        "\n",
        "    print(f\"Topic {res[0] + 1} : {joined_words}\")\n",
        "\n",
        "clean_print_result(result_lsi)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1 : covid, coronavirus, ha, claim\n",
            "Topic 2 : coronavirus, covid, ha, claim\n",
            "Topic 3 : coronavirus, claim, post, facebook, ha\n",
            "Topic 4 : video, show, ha, people, post\n",
            "Topic 5 : wa, people, video, show, coronavirus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zcmfh5UkdZm"
      },
      "source": [
        "# Exercise 8 (Optional)\n",
        "\n",
        "The top-scored words contributing to each topic (if no stopword removal is applied) are english common words (e.g., *to, for, in, of, on*..). Repeat the same procedure of Ex. 7 by adding a preliminary preprocessing step to **remove stopwords**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz2NUP6O1JAK"
      },
      "source": [
        "# already done above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zssKPqSdyYgY"
      },
      "source": [
        "# Exercise 9 (Optional)\n",
        "\n",
        "Leveraging the same corpus used for LSI model generation, apply LDA modelling setting the number of topics to 5. Display the words most contributing to the those topics according to the LDA model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzCXdEUW1MHs"
      },
      "source": [
        "lda_model  = LdaModel(corpus_bow, id2word=dct, num_topics=5)  \n",
        "result_lda = lda_model.print_topics(num_topics=5, num_words=5)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZHz3OtMBhk8",
        "outputId": "85f9ed51-aca6-4676-816d-4f36d64f6274"
      },
      "source": [
        "clean_print_result(result_lda)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1 : coronavirus, covid, ha, video\n",
            "Topic 2 : coronavirus, outbreak, show, video, new\n",
            "Topic 3 : coronavirus, people, covid, lockdown\n",
            "Topic 4 : coronavirus, china, people, wa, chinese\n",
            "Topic 5 : covid, coronavirus, cure, ha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBhdPyiKDNZ0"
      },
      "source": [
        "# Exercise 10 (Optional)\n",
        "\n",
        "Using [pyLDAvis]() library build an interactive visualization for the trained LDA model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5awvObKB6U3"
      },
      "source": [
        "!pip install pyLDAvis==3.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aM6yrdPDREK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        },
        "outputId": "03843ad5-8dc3-4f7f-a271-41df6f63b4c9"
      },
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = gensim_models.prepare(lda_model, corpus_bow, dct, mds=\"mmds\", R=15)\n",
        "vis"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1174140226699746512872604471\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1174140226699746512872604471_data = {\"mdsDat\": {\"x\": [0.07435616638301722, -0.011284162527417225, -0.1673619362889809, -0.07395826551194118, 0.1782481979453221], \"y\": [0.0960187642509851, -0.15123457099637938, -0.04526681927291567, 0.1672423339277467, -0.06675970790943676], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [26.575763184135, 24.914481234832454, 18.001751117161124, 16.133402460268353, 14.374602003603068]}, \"tinfo\": {\"Term\": [\"coronavirus\", \"19\", \"covid\", \"china\", \"water\", \"wuhan\", \"muslim\", \"lockdown\", \"outbreak\", \"cure\", \"drinking\", \"chinese\", \"vaccine\", \"predicted\", \"bat\", \"breath\", \"april\", \"korea\", \"coffin\", \"8\", \"nigeria\", \"wife\", \"48\", \"elderly\", \"putin\", \"best\", \"strain\", \"responsible\", \"suspected\", \"following\", \"france\", \"viewed\", \"cured\", \"ecuador\", \"youtube\", \"alongside\", \"multiple\", \"thousand\", \"twitter\", \"dead\", \"hospital\", \"patient\", \"person\", \"facebook\", \"claim\", \"health\", \"ha\", \"video\", \"19\", \"covid\", \"coronavirus\", \"show\", \"time\", \"infected\", \"novel\", \"post\", \"wa\", \"people\", \"hot\", \"c\", \"disinfectant\", \"cold\", \"buy\", \"team\", \"patent\", \"side\", \"boiled\", \"helicopter\", \"professor\", \"nose\", \"admitted\", \"approval\", \"prince\", \"tea\", \"drinking\", \"different\", \"self\", \"lemon\", \"19\", \"covid\", \"taiwan\", \"water\", \"drink\", \"company\", \"cure\", \"every\", \"prevent\", \"say\", \"new\", \"case\", \"coronavirus\", \"virus\", \"ha\", \"show\", \"wa\", \"people\", \"supermarket\", \"usa\", \"leave\", \"dettol\", \"meeting\", \"patented\", \"manufactured\", \"recommended\", \"barcelona\", \"skin\", \"lankan\", \"ship\", \"truck\", \"plane\", \"soup\", \"bat\", \"sex\", \"full\", \"lab\", \"japanese\", \"vaccine\", \"wuhan\", \"china\", \"chinese\", \"developed\", \"coronavirus\", \"said\", \"doctor\", \"scientist\", \"wa\", \"president\", \"people\", \"new\", \"virus\", \"ha\", \"novel\", \"video\", \"show\", \"book\", \"weapon\", \"lion\", \"ago\", \"turkey\", \"steam\", \"flight\", \"asking\", \"simpson\", \"graphic\", \"shop\", \"seek\", \"present\", \"bio\", \"arrived\", \"muslim\", \"ghana\", \"class\", \"predicted\", \"mosque\", \"500\", \"lockdown\", \"avoid\", \"airport\", \"biological\", \"coronavirus\", \"people\", \"map\", \"india\", \"case\", \"home\", \"outbreak\", \"mask\", \"video\", \"covid\", \"19\", \"wa\", \"state\", \"government\", \"ha\", \"market\", \"sanitizer\", \"chicken\", \"warm\", \"originated\", \"ice\", \"central\", \"ibuprofen\", \"shopping\", \"weed\", \"iranian\", \"distributed\", \"malaria\", \"indonesia\", \"bus\", \"garlic\", \"korean\", \"li\", \"temperature\", \"eat\", \"sold\", \"onion\", \"protection\", \"white\", \"coronavirus\", \"hand\", \"outbreak\", \"food\", \"woman\", \"salt\", \"4\", \"india\", \"20\", \"cure\", \"due\", \"new\", \"novel\", \"show\", \"video\", \"water\", \"kill\", \"prevent\", \"ha\", \"wuhan\", \"covid\", \"19\"], \"Freq\": [4520.0, 2382.0, 2397.0, 745.0, 318.0, 392.0, 160.0, 340.0, 398.0, 404.0, 194.0, 484.0, 379.0, 139.0, 127.0, 86.56033338626065, 65.62116288698755, 57.73043912300338, 48.23862849983425, 39.84750343368219, 38.1217849368054, 36.33186603706985, 36.13445012603289, 35.73277152830183, 37.360789912414845, 31.26393448074969, 31.65019554248689, 30.477892515443944, 29.454032435403054, 29.574904737681408, 71.1223586690942, 70.85268289069828, 47.90433607132804, 75.96275702308327, 49.05599389020234, 88.63433939639998, 128.45610432877268, 133.23323310052848, 120.78211755887901, 78.60900140042308, 280.588247443646, 265.34428983121853, 100.74708853053805, 217.16666613526473, 324.9552750409826, 198.60184206456907, 443.80814230713395, 405.7615178582986, 728.3234039783304, 718.0374952028927, 1076.2328467451298, 356.67368269212255, 167.19740938750803, 233.03136311354, 218.07595989501115, 187.89497949387064, 244.0716823407042, 233.05262777627985, 104.38586106060947, 87.67586129106783, 60.01346977909048, 55.84022699983025, 45.36505233580319, 45.32848159923451, 41.88952033820898, 41.38967008507634, 38.51144987592163, 36.520670732556894, 36.50429655551316, 31.466424099161145, 36.858035931035786, 33.526049144353976, 27.94460255809463, 100.51784965668621, 183.68869520161925, 36.14259285893641, 40.09384247943217, 69.23697088590994, 1301.3029043002023, 1304.4435015692072, 64.93044248987299, 223.58115589020017, 74.85753851216195, 93.97806049679596, 242.32434972896726, 104.10749083290177, 151.3651786474133, 167.5278833021724, 224.38066065033905, 161.12823177910158, 495.8921576374126, 162.99019909097308, 225.89238219511327, 151.86818451695126, 148.37889009883182, 149.31075253401968, 66.67426416341168, 43.64020129448705, 32.69795699468278, 32.46275736453483, 30.014509932552905, 41.64024959705292, 24.758464235078673, 25.669646340093955, 23.272723667879443, 21.26395808964781, 19.438958595862427, 20.97937852582278, 18.829664118827672, 18.441286122794583, 54.97754722709903, 116.81310183873762, 25.316729228453333, 30.534990684795908, 88.4721724800628, 44.17185369614391, 225.74576835945663, 229.3278538423434, 381.5398898141599, 250.23746950259942, 60.1784118144418, 1187.2304005793342, 132.2248806318028, 160.2702230662007, 77.89575529614032, 252.57509718026995, 154.5187062807615, 271.5675228177441, 185.40476471631536, 152.33495963730672, 215.382385116543, 146.09404823537432, 178.38307224274854, 140.81099476462512, 58.82911190915584, 62.82969286083093, 36.25511514953376, 36.438947630712505, 35.7940257530124, 28.914249545717478, 28.20795931126575, 27.982016792078653, 29.83132674466392, 23.75895341175212, 29.26399127889433, 21.867310574614525, 16.807169914931492, 20.51389586313954, 34.22337545517609, 146.76455315703672, 26.95993509748619, 35.32378770997988, 109.8476275452907, 47.5665072671062, 55.45489688099139, 190.62059383751793, 61.32768725734767, 43.42571206583519, 40.557728776959685, 698.7423424188474, 272.13020325730866, 42.18811388679215, 116.68929500386263, 129.3970952982892, 78.20699180268714, 111.97768235957223, 95.3486663183504, 149.6384617763407, 196.19279208185415, 174.97885165659835, 116.70805390758322, 86.76235714332198, 87.20142054661179, 87.36062052587486, 89.17463430286209, 44.46008742730964, 36.436942164617, 56.22297251316278, 28.50956666221428, 27.38173245451001, 21.403880173442566, 23.514807227023876, 18.227335041463096, 17.473694642261915, 17.30678629138088, 16.3759305295937, 15.936490890545468, 16.655485618994998, 15.502213621308872, 73.59989222216664, 34.69315675363538, 24.281511329227104, 35.09503093378643, 27.243119634042277, 24.880667102698332, 22.277478304674723, 27.379170770314335, 36.47185552693512, 1062.7518852952685, 55.42443261525991, 164.30692778367523, 78.64298150825157, 61.197490211227745, 42.836351933534196, 48.86089777863622, 106.40597234671088, 73.78439021359407, 105.9955072173472, 91.43388730335273, 121.20367849441249, 108.15554769581229, 130.59817042349627, 127.6736879252042, 87.05596369456332, 84.50013680309455, 80.10995965716982, 111.16983273709138, 85.71519414167187, 94.71429676312209, 92.21942554596765], \"Total\": [4520.0, 2382.0, 2397.0, 745.0, 318.0, 392.0, 160.0, 340.0, 398.0, 404.0, 194.0, 484.0, 379.0, 139.0, 127.0, 87.35714327777717, 66.39361785097752, 58.56353743505276, 49.00572030881193, 40.615117110550216, 38.89561683884492, 37.102905390174286, 36.90278773269172, 36.56181074017028, 38.249528216975015, 32.04226580301703, 32.46041584519316, 31.25826135893131, 30.227297775687358, 30.42372811001719, 74.53339412552828, 75.03696252561056, 50.471910334824095, 82.516124171343, 52.132962072019865, 102.68855669208001, 164.4523140455439, 172.81770557333385, 156.66959905048037, 94.51746169514247, 459.43046623836784, 436.5162483576448, 129.26239093856725, 351.2596794291644, 637.1375328624856, 334.04902812913474, 1083.6133628817565, 957.628227167352, 2382.9142838371154, 2397.259900747487, 4520.849632675992, 855.0989141849152, 270.9614227608431, 521.8047247511494, 514.6937719952409, 390.12019844352693, 785.1668475980116, 994.526135433931, 105.67002404519874, 88.81171784112378, 60.80611650379889, 56.622237725927235, 46.1576693534026, 46.122618125101454, 42.69103625610019, 42.2069919955169, 39.30550814353264, 37.31950393027366, 37.40966648684783, 32.255725530473576, 37.79254975255061, 34.45203867140309, 28.74805344983092, 104.61544946604798, 194.42663606688998, 37.31513651766681, 41.88550126281419, 78.09675291888641, 2382.9142838371154, 2397.259900747487, 73.38989920056764, 318.0758675456261, 87.47018464265821, 117.14068334037545, 404.6376853694819, 137.44271053465405, 253.01360917168267, 379.624533365324, 652.7880184278324, 420.8151747309662, 4520.849632675992, 459.8967436772044, 1083.6133628817565, 855.0989141849152, 785.1668475980116, 994.526135433931, 67.48818210868497, 44.4501805931009, 33.51262093466936, 33.29596700041615, 30.829751121910835, 42.918455104463945, 25.55496857034858, 26.51744366913852, 24.145340499919847, 22.088025144264233, 20.24385377396401, 21.881652908547075, 19.64087761364586, 19.257324783394846, 57.45378087255118, 127.19638253388861, 26.773606982511907, 33.028018308966196, 118.84991383174453, 52.961658315278, 379.44432330184566, 392.5993393959894, 745.563230657812, 484.48437843578597, 78.83710541382871, 4520.849632675992, 244.56682308126477, 328.3024178129033, 124.6114314391462, 785.1668475980116, 365.19435250916337, 994.526135433931, 652.7880184278324, 459.8967436772044, 1083.6133628817565, 514.6937719952409, 957.628227167352, 855.0989141849152, 59.685679989151275, 64.05628245830825, 37.04031617679662, 37.23635308183409, 36.57987064643693, 29.7090360032958, 28.9978740105504, 28.77285150917176, 30.785177511782678, 24.556128876730327, 30.324190018112567, 22.8056115167234, 17.59991353517129, 21.4818498615565, 35.88057659493779, 160.5259721378764, 28.548598992222495, 38.26884661608907, 139.64264330296444, 55.33384142341622, 68.88888468790012, 340.119326155011, 84.80834723279156, 52.673163906227764, 48.37239443275649, 4520.849632675992, 994.526135433931, 51.64023794543905, 334.8969514200866, 420.8151747309662, 177.16428206303294, 398.0859339795478, 324.51216733941664, 957.628227167352, 2397.259900747487, 2382.9142838371154, 785.1668475980116, 294.19336496924797, 401.1343549250675, 1083.6133628817565, 89.99787057861552, 45.367987454850926, 37.282316300812674, 57.53856788152377, 29.334384409381414, 28.207226942183276, 22.22449162664891, 24.43958897655802, 19.03571808814266, 18.301116247494434, 18.1378904635271, 17.18900532676906, 16.750826424852132, 17.52352574932823, 16.31456017929799, 79.17084618928747, 36.87905107658446, 26.46041139827109, 39.745558302673565, 30.361575199474053, 27.44675481916202, 24.39733976105827, 31.840950510078706, 46.37269534107185, 4520.849632675992, 82.92182311653407, 398.0859339795478, 149.66211390598988, 104.71929548990822, 61.03703453958602, 76.91235156771884, 334.8969514200866, 188.72507272040792, 404.6376853694819, 310.23249303355675, 652.7880184278324, 514.6937719952409, 855.0989141849152, 957.628227167352, 318.0758675456261, 292.32492404236496, 253.01360917168267, 1083.6133628817565, 392.5993393959894, 2397.259900747487, 2382.9142838371154], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.7846, -6.0615, -6.1897, -6.3693, -6.5604, -6.6047, -6.6527, -6.6582, -6.6694, -6.6248, -6.803, -6.7907, -6.8284, -6.8626, -6.8585, -5.981, -5.9848, -6.3762, -5.9152, -6.3525, -5.7609, -5.3899, -5.3533, -5.4515, -5.881, -4.6086, -4.6644, -5.6328, -4.8648, -4.4618, -4.9541, -4.15, -4.2397, -3.6547, -3.6689, -3.2642, -4.3686, -5.1263, -4.7943, -4.8606, -5.0096, -4.748, -4.7942, -5.5328, -5.7072, -6.0863, -6.1584, -6.3661, -6.367, -6.4459, -6.4579, -6.5299, -6.583, -6.5835, -6.732, -6.5738, -6.6686, -6.8507, -5.5706, -4.9676, -6.5934, -6.4897, -5.9434, -3.0098, -3.0074, -6.0076, -4.7711, -5.8653, -5.6378, -4.6906, -5.5355, -5.1612, -5.0597, -4.7675, -5.0987, -3.9745, -5.0872, -4.7608, -5.1579, -5.1811, -5.1749, -5.6561, -6.0799, -6.3686, -6.3758, -6.4542, -6.1268, -6.6467, -6.6106, -6.7086, -6.7989, -6.8886, -6.8124, -6.9205, -6.9413, -5.849, -5.0953, -6.6244, -6.437, -5.3732, -6.0678, -4.4365, -4.4208, -3.9117, -4.3335, -5.7586, -2.7765, -4.9714, -4.779, -5.5005, -4.3242, -4.8156, -4.2517, -4.6334, -4.8298, -4.4835, -4.8717, -4.672, -4.9085, -5.6717, -5.6059, -6.1558, -6.1507, -6.1685, -6.382, -6.4067, -6.4148, -6.3508, -6.5784, -6.37, -6.6613, -6.9245, -6.7252, -6.2134, -4.7575, -6.452, -6.1818, -5.0472, -5.8842, -5.7308, -4.496, -5.6301, -5.9753, -6.0436, -3.197, -4.1401, -6.0042, -4.9868, -4.8834, -5.387, -5.028, -5.1888, -4.7381, -4.4672, -4.5817, -4.9867, -5.2832, -5.2781, -5.2763, -5.1403, -5.8363, -6.0353, -5.6016, -6.2807, -6.321, -6.5673, -6.4733, -6.728, -6.7702, -6.7798, -6.8351, -6.8623, -6.8182, -6.8899, -5.3323, -6.0844, -6.4412, -6.0728, -6.3261, -6.4168, -6.5273, -6.3211, -6.0344, -2.6623, -5.6159, -4.5292, -5.266, -5.5168, -5.8735, -5.7419, -4.9636, -5.3298, -4.9675, -5.1153, -4.8334, -4.9473, -4.7588, -4.7814, -5.1644, -5.1941, -5.2475, -4.9198, -5.1799, -5.08, -5.1067], \"loglift\": [15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.316, 1.3135, 1.3108, 1.3094, 1.3061, 1.3051, 1.3042, 1.3041, 1.3022, 1.3017, 1.3006, 1.2999, 1.2999, 1.2993, 1.2969, 1.2783, 1.2678, 1.273, 1.2424, 1.2643, 1.178, 1.0781, 1.065, 1.065, 1.1409, 0.8321, 0.8274, 1.0759, 0.8443, 0.6519, 0.8052, 0.4325, 0.4665, 0.1398, 0.1196, -0.1101, 0.4508, 0.8424, 0.5191, 0.4664, 0.5946, 0.1567, -0.1258, 1.3775, 1.3768, 1.3766, 1.3758, 1.3724, 1.3724, 1.3708, 1.3702, 1.3693, 1.3681, 1.3652, 1.3649, 1.3647, 1.3625, 1.3614, 1.3498, 1.3329, 1.3578, 1.346, 1.2693, 0.7848, 0.7812, 1.2673, 1.0372, 1.234, 1.1694, 0.877, 1.1119, 0.876, 0.5717, 0.3218, 0.4297, -0.8204, 0.3524, -0.1783, -0.3385, -0.2764, -0.5065, 1.7026, 1.6963, 1.6901, 1.6894, 1.6879, 1.6845, 1.683, 1.6822, 1.6779, 1.6767, 1.6741, 1.6726, 1.6725, 1.6714, 1.6706, 1.6295, 1.6588, 1.6362, 1.4195, 1.5332, 1.1954, 1.1771, 1.0448, 1.054, 1.4446, 0.3776, 1.0997, 0.9976, 1.2449, 0.5805, 0.8546, 0.4166, 0.456, 0.6098, 0.0991, 0.4554, 0.0342, -0.0891, 1.8098, 1.8049, 1.8029, 1.8026, 1.8026, 1.7972, 1.7967, 1.7964, 1.7928, 1.7913, 1.7887, 1.7823, 1.7782, 1.7782, 1.777, 1.7347, 1.767, 1.7442, 1.5843, 1.673, 1.6074, 1.2453, 1.5001, 1.6312, 1.6481, -0.0429, 0.5283, 1.6221, 0.77, 0.645, 1.0066, 0.5559, 0.5995, -0.032, -0.6787, -0.7871, -0.0819, 0.6032, 0.2982, -0.6937, 1.9305, 1.9195, 1.9168, 1.9166, 1.9112, 1.91, 1.9021, 1.9011, 1.8963, 1.8934, 1.8928, 1.8912, 1.8899, 1.8889, 1.8886, 1.8667, 1.8786, 1.8538, 1.8153, 1.8313, 1.8416, 1.8488, 1.7887, 1.6995, 0.4919, 1.5368, 1.0548, 1.2962, 1.4025, 1.5856, 1.486, 0.7931, 1.0006, 0.6001, 0.718, 0.2559, 0.3797, 0.0606, -0.0753, 0.644, 0.6986, 0.7897, -0.3373, 0.4179, -1.2915, -1.3122]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 5, 1, 2, 4, 1, 2, 4, 2, 3, 4, 1, 2, 3, 4, 5, 2, 1, 1, 4, 4, 1, 3, 4, 3, 1, 3, 4, 1, 4, 2, 4, 2, 4, 1, 5, 2, 2, 4, 1, 2, 3, 4, 5, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 1, 2, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 2, 2, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 3, 4, 5, 1, 2, 4, 5, 1, 1, 2, 3, 5, 1, 2, 3, 4, 5, 4, 1, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 5, 3, 5, 1, 4, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 1, 2, 3, 5, 1, 2, 5, 1, 2, 3, 4, 5, 3, 3, 1, 2, 3, 2, 5, 4, 1, 2, 3, 4, 5, 5, 3, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 3, 5, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 4, 5, 2, 2, 1, 5, 1, 3, 1, 1, 2, 3, 4, 5, 2, 5, 5, 1, 2, 3, 4, 5, 2, 3, 5, 4, 2, 4, 2, 3, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 3, 1, 5, 2, 3, 1, 2, 3, 4, 5, 4, 1, 3, 1, 2, 4, 5, 1, 2, 4, 2, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 5, 4, 5, 5, 3, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2], \"Freq\": [0.30550826143344506, 0.5459701210507034, 0.03609026165285203, 0.07343948592150122, 0.03860818688444636, 0.3603124853513265, 0.21194852079489793, 0.03709099113910713, 0.39210476347056117, 0.09101268986473163, 0.27303806959419485, 0.6370888290531214, 0.9755360559957926, 0.18870968892726703, 0.7983871454615143, 0.984854971392156, 0.9790289420073562, 0.9667971490355953, 0.09492499840908226, 0.07593999872726581, 0.8163549863181075, 0.8666983242044558, 0.03895273367211037, 0.07790546734422074, 0.009738183418027593, 0.019476366836055185, 0.9868791894809319, 0.9940714504839756, 0.027870232167369488, 0.9475878936905625, 0.9731395579987823, 0.2240345510784056, 0.04716516864808539, 0.7192688218833022, 0.9525647401856416, 0.007861858805092768, 0.9198374801958538, 0.0707567292458349, 0.9674721566375967, 0.9775694428244371, 0.14471063676061874, 0.8475908724550526, 0.9922273452764684, 0.9885118174195903, 0.9959116877638554, 0.9807190524389897, 0.9749192415990722, 0.9908602393821965, 0.01125977544752496, 0.2661500980129896, 0.3825907658936726, 0.023763401608302644, 0.3065478807471041, 0.019010721286642114, 0.9449035034312935, 0.9656052405524835, 0.21057905425604018, 0.09254748244373741, 0.5123643230943143, 0.0858411431362202, 0.0992538217512546, 0.2724546050920719, 0.061921501157289074, 0.5160125096440756, 0.11352275212169664, 0.035088850655797144, 0.5100939486956033, 0.14282630563476892, 0.20717661916252195, 0.05336367463277081, 0.08632359131771748, 0.052261831145941975, 0.9145820450539845, 0.9794774915566115, 0.9890107182104123, 0.1280511567139704, 0.802453915407548, 0.051220462685588164, 0.01707348756186272, 0.238008358478203, 0.1097138901535211, 0.26256126534723695, 0.15461695406715975, 0.23513279280885668, 0.2995086180585264, 0.5439543704015577, 0.03504000545531507, 0.08176001272906849, 0.03962857759827299, 0.024713466791578795, 0.5980658963562069, 0.11121060056210458, 0.004942693358315759, 0.2619627479907352, 0.9510240385508343, 0.03962600160628476, 0.8358243924790041, 0.021160111202000103, 0.03174016680300016, 0.10580055601000052, 0.021160111202000103, 0.9610773580956531, 0.07610629498007354, 0.15221258996014708, 0.7610629498007353, 0.012684382496678923, 0.9647559505230764, 0.9867428385473601, 0.9308275665656245, 0.1675284646588988, 0.24672373886128734, 0.4873555335531602, 0.07005735794826677, 0.02741374876236526, 0.8574350255049462, 0.12575713707405878, 0.011432467006732616, 0.020573312797655213, 0.9463723886921397, 0.005143328199413803, 0.025716640997069013, 0.151499282168732, 0.2610945075673892, 0.10637183641634375, 0.18695656097417993, 0.2933283973905237, 0.06587273508900966, 0.03293636754450483, 0.8892819237016304, 0.9210321105507525, 0.012118843559878321, 0.024237687119756643, 0.036356530679634964, 0.9846339464923431, 0.18916972678186889, 0.7566789071274755, 0.007275758722379572, 0.04365455233427744, 0.6177765701792157, 0.11387586547082318, 0.16796690156946417, 0.07117241591926449, 0.03131586300447637, 0.9655880286193622, 0.9860724462010402, 0.3207224510416254, 0.06013545957030476, 0.020045153190101587, 0.06681717730033862, 0.5278557006726751, 0.9525931407393393, 0.04025041439743687, 0.03027732365427833, 0.03027732365427833, 0.9385970332826282, 0.03027732365427833, 0.06315456055687005, 0.9346874962416767, 0.03502798859840479, 0.9457556921569293, 0.3764324799061577, 0.18696977478782667, 0.14458995916925263, 0.21688493875387893, 0.07478790991513067, 0.9773527464560051, 0.409740240577348, 0.20856147380738885, 0.19841025163092302, 0.08028693903204792, 0.102435060144337, 0.0964764123523576, 0.1326550669844917, 0.0120595515440447, 0.0844168608083129, 0.6632753349224585, 0.5957209368771812, 0.18859507046865534, 0.110762184243496, 0.020955007829850596, 0.08382003131940238, 0.9914386876398301, 0.20884570845288014, 0.16933435820503795, 0.056444786068345985, 0.44026933133309865, 0.12417852935036117, 0.6116268307165503, 0.18936489064889636, 0.06529823815479185, 0.004353215876986123, 0.1305964763095837, 0.9841958581888425, 0.009463421713354256, 0.9820132418356272, 0.9572015021307219, 0.22992147188408732, 0.04478989712027675, 0.05971986282703567, 0.34936119753815864, 0.316515272983289, 0.9701244055096447, 0.4465271948450037, 0.1686454641474692, 0.21655610737118205, 0.12265124665270488, 0.04599421749476433, 0.937264453889208, 0.1321710879657386, 0.03776316799021103, 0.8307896957846427, 0.06841701940236035, 0.3010348853703856, 0.33866424604168377, 0.2907723324600315, 0.9903773327272499, 0.054231330297699984, 0.9490482802097497, 0.008413973285800586, 0.15986549243021111, 0.7404296491504515, 0.0588978130006041, 0.016827946571601173, 0.9385564730978371, 0.9847036453618868, 0.03841388902706222, 0.8835194476224311, 0.06402314837843703, 0.07558461468708226, 0.9070153762449872, 0.9719139498747499, 0.11760578398232452, 0.01764086759734868, 0.1146656393827664, 0.5615676185155996, 0.19110939897127735, 0.9551767533249477, 0.978283339741904, 0.11618846540442655, 0.058094232702213276, 0.8133192578309859, 0.9889122867885651, 0.10169110227994733, 0.2711762727465262, 0.17564826757445448, 0.2927471126240908, 0.1571589762508277, 0.9730860259419634, 0.10843273927229848, 0.018072123212049745, 0.8674619141783878, 0.7783411303324763, 0.03648474048433483, 0.14593896193733932, 0.018242370242167415, 0.012161580161444942, 0.024918086131036687, 0.012459043065518344, 0.024918086131036687, 0.9157396653155983, 0.024918086131036687, 0.11182803289774283, 0.34314355300129307, 0.2833998093983894, 0.07506265221903287, 0.18535879425516277, 0.9769738363436757, 0.9610696857744765, 0.4235528227880242, 0.05828708570477397, 0.28366381709656663, 0.02331483428190959, 0.2098335085371863, 0.04098807533090745, 0.901737657279964, 0.9886009399510537, 0.06782455167428036, 0.20849769588760259, 0.03014424518856905, 0.28134628842664444, 0.4119713509104437, 0.983813083103565, 0.9785999961501779, 0.6070793492728849, 0.14203365907516552, 0.18785096845425114, 0.03207211656535995, 0.02749038562745139, 0.23428243029363688, 0.1498200949088064, 0.2734970860080224, 0.2734970860080224, 0.0683742715020056, 0.7813564275474439, 0.1547240450588998, 0.01547240450588998, 0.03094480901177996, 0.03094480901177996, 0.9347092704964394, 0.4819027590728926, 0.12816562741300336, 0.2819643803086074, 0.051266250965201335, 0.05639287606172147, 0.1933506797162355, 0.014322272571573001, 0.7877249914365151, 0.007161136285786501, 0.9659138362258181, 0.07940977126493855, 0.32585388898371337, 0.4244315360712233, 0.09310111113820381, 0.07940977126493855, 0.06719006165579272, 0.5968058417661588, 0.015809426271951227, 0.31618852543902454, 0.97397898779003, 0.9890491809919808, 0.12562439047583923, 0.8479646357119148, 0.9673321927034781, 0.9804866684890622, 0.9597462781284285, 0.20035424013222863, 0.03679975839163383, 0.5397297897439629, 0.15537675765356507, 0.06542179269623792, 0.2949029246878953, 0.7044903200877499, 0.9698468560852007, 0.14224581199032832, 0.4425425261921326, 0.2160028996890171, 0.10009890473393475, 0.10009890473393475, 0.34507267514215967, 0.6259457828160105, 0.02407483780061579, 0.964674855741858, 0.9549843930246066, 0.023874609825615165, 0.03735021585448625, 0.9337553963621562, 0.9597081211263205, 0.9563322213281993, 0.9455908054875111, 0.41749555996138094, 0.17775721320484567, 0.164893204354495, 0.08770915125239095, 0.1531986508541762, 0.9714030320937085, 0.9744949493475501, 0.9507414023137887, 0.07286835959942685, 0.9108544949928357, 0.034810589827614105, 0.957291220259388, 0.33311424277105617, 0.19375012079541024, 0.050986873893529, 0.29572386858246824, 0.12576762227070487, 0.9761339949496463, 0.9858160829673616, 0.9927664060072209, 0.9593977012171261, 0.885680464315139, 0.08175511978293591, 0.02725170659431197, 0.00955881760393852, 0.9654405779977905, 0.028676452811815557, 0.9756601387619301, 0.02516004410819241, 0.07548013232457723, 0.8806015437867344, 0.7695970708485218, 0.06943732970061851, 0.09258310626749135, 0.04629155313374567, 0.01735933242515463, 0.6163238969533981, 0.13655080351662113, 0.11440742997338527, 0.09226405643014941, 0.04059618482926574, 0.9673702150050262, 0.9841478212965356, 0.7723259696414535, 0.012765718506470305, 0.2042514961035249, 0.006382859253235153, 0.012765718506470305, 0.9898722437773227, 0.1502196672860931, 0.15549053280490338, 0.5956078036255621, 0.03689605863167199, 0.06325038622572342, 0.4239641110005092, 0.10024767156662286, 0.1858758910297799, 0.1566369868228482, 0.13366356208883048, 0.9462003472724163, 0.026653530909082148, 0.026653530909082148, 0.013326765454541074, 0.05653442942890038, 0.35442738449656774, 0.33050897204587915, 0.10654565546215841, 0.15220807923165486, 0.3107619746636612, 0.18849496823861417, 0.3222245065160093, 0.14901291408052605, 0.02929313695600085, 0.017379647023177135, 0.9732602332979194, 0.01886342414562254, 0.7042345014365747, 0.003143904024270423, 0.2735196501115268, 0.9835100880386598, 0.015611271238708885, 0.9289050880886806, 0.1940797258775853, 0.7763189035103412, 0.9702744197906841, 0.17188809298029184, 0.05729603099343061, 0.019098676997810204, 0.16233875448138674, 0.5825096484332113, 0.020377008306503852, 0.1477333102221529, 0.5832918627736727, 0.028018386421442793, 0.2190528392949164, 0.9399043916267066, 0.0383634445561921], \"Term\": [\"19\", \"19\", \"19\", \"19\", \"19\", \"20\", \"20\", \"20\", \"20\", \"4\", \"4\", \"4\", \"48\", \"500\", \"500\", \"8\", \"admitted\", \"ago\", \"airport\", \"airport\", \"airport\", \"alongside\", \"alongside\", \"alongside\", \"alongside\", \"alongside\", \"approval\", \"april\", \"arrived\", \"arrived\", \"asking\", \"avoid\", \"avoid\", \"avoid\", \"barcelona\", \"bat\", \"bat\", \"bat\", \"best\", \"bio\", \"biological\", \"biological\", \"boiled\", \"book\", \"breath\", \"bus\", \"buy\", \"c\", \"c\", \"case\", \"case\", \"case\", \"case\", \"case\", \"central\", \"chicken\", \"china\", \"china\", \"china\", \"china\", \"china\", \"chinese\", \"chinese\", \"chinese\", \"chinese\", \"chinese\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"class\", \"class\", \"coffin\", \"cold\", \"company\", \"company\", \"company\", \"company\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"cure\", \"cure\", \"cure\", \"cure\", \"cure\", \"cured\", \"cured\", \"dead\", \"dead\", \"dead\", \"dead\", \"dead\", \"dettol\", \"developed\", \"developed\", \"developed\", \"developed\", \"different\", \"disinfectant\", \"distributed\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"doctor\", \"drink\", \"drink\", \"drink\", \"drinking\", \"drinking\", \"drinking\", \"drinking\", \"due\", \"due\", \"due\", \"due\", \"due\", \"eat\", \"eat\", \"eat\", \"ecuador\", \"ecuador\", \"ecuador\", \"ecuador\", \"elderly\", \"every\", \"every\", \"every\", \"every\", \"facebook\", \"facebook\", \"facebook\", \"facebook\", \"facebook\", \"flight\", \"following\", \"food\", \"food\", \"food\", \"food\", \"food\", \"france\", \"france\", \"full\", \"full\", \"full\", \"full\", \"garlic\", \"garlic\", \"ghana\", \"ghana\", \"government\", \"government\", \"government\", \"government\", \"government\", \"graphic\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"health\", \"health\", \"health\", \"health\", \"health\", \"helicopter\", \"home\", \"home\", \"home\", \"home\", \"home\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hot\", \"hot\", \"ibuprofen\", \"ice\", \"india\", \"india\", \"india\", \"india\", \"india\", \"indonesia\", \"infected\", \"infected\", \"infected\", \"infected\", \"infected\", \"iranian\", \"japanese\", \"japanese\", \"japanese\", \"kill\", \"kill\", \"kill\", \"kill\", \"korea\", \"korean\", \"korean\", \"lab\", \"lab\", \"lab\", \"lab\", \"lab\", \"lankan\", \"leave\", \"lemon\", \"lemon\", \"lemon\", \"li\", \"li\", \"lion\", \"lockdown\", \"lockdown\", \"lockdown\", \"lockdown\", \"lockdown\", \"malaria\", \"manufactured\", \"map\", \"map\", \"map\", \"market\", \"mask\", \"mask\", \"mask\", \"mask\", \"mask\", \"meeting\", \"mosque\", \"mosque\", \"mosque\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"muslim\", \"muslim\", \"muslim\", \"muslim\", \"muslim\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nigeria\", \"nose\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"onion\", \"onion\", \"originated\", \"outbreak\", \"outbreak\", \"outbreak\", \"outbreak\", \"outbreak\", \"patent\", \"patented\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"people\", \"people\", \"people\", \"people\", \"people\", \"person\", \"person\", \"person\", \"person\", \"person\", \"plane\", \"post\", \"post\", \"post\", \"post\", \"post\", \"predicted\", \"predicted\", \"predicted\", \"predicted\", \"present\", \"president\", \"president\", \"president\", \"president\", \"president\", \"prevent\", \"prevent\", \"prevent\", \"prevent\", \"prince\", \"professor\", \"protection\", \"protection\", \"putin\", \"recommended\", \"responsible\", \"said\", \"said\", \"said\", \"said\", \"said\", \"salt\", \"salt\", \"sanitizer\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scientist\", \"scientist\", \"scientist\", \"seek\", \"self\", \"self\", \"sex\", \"sex\", \"ship\", \"shop\", \"shopping\", \"show\", \"show\", \"show\", \"show\", \"show\", \"side\", \"simpson\", \"skin\", \"sold\", \"sold\", \"soup\", \"soup\", \"state\", \"state\", \"state\", \"state\", \"state\", \"steam\", \"strain\", \"supermarket\", \"suspected\", \"taiwan\", \"taiwan\", \"taiwan\", \"tea\", \"tea\", \"tea\", \"team\", \"temperature\", \"temperature\", \"temperature\", \"thousand\", \"thousand\", \"thousand\", \"thousand\", \"thousand\", \"time\", \"time\", \"time\", \"time\", \"time\", \"truck\", \"turkey\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"twitter\", \"usa\", \"vaccine\", \"vaccine\", \"vaccine\", \"vaccine\", \"vaccine\", \"video\", \"video\", \"video\", \"video\", \"video\", \"viewed\", \"viewed\", \"viewed\", \"viewed\", \"virus\", \"virus\", \"virus\", \"virus\", \"virus\", \"wa\", \"wa\", \"wa\", \"wa\", \"wa\", \"warm\", \"warm\", \"water\", \"water\", \"water\", \"water\", \"weapon\", \"weapon\", \"weed\", \"white\", \"white\", \"wife\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"wuhan\", \"wuhan\", \"wuhan\", \"wuhan\", \"wuhan\", \"youtube\", \"youtube\"]}, \"R\": 15, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 5, 4, 3, 2]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1174140226699746512872604471\", ldavis_el1174140226699746512872604471_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1174140226699746512872604471\", ldavis_el1174140226699746512872604471_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1174140226699746512872604471\", ldavis_el1174140226699746512872604471_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "0      0.074356  0.096019       1        1  26.575763\n",
              "4     -0.011284 -0.151235       2        1  24.914481\n",
              "3     -0.167362 -0.045267       3        1  18.001751\n",
              "2     -0.073958  0.167242       4        1  16.133402\n",
              "1      0.178248 -0.066760       5        1  14.374602, topic_info=             Term         Freq        Total Category  logprob  loglift\n",
              "4     coronavirus  4520.000000  4520.000000  Default  15.0000  15.0000\n",
              "0              19  2382.000000  2382.000000  Default  14.0000  14.0000\n",
              "5           covid  2397.000000  2397.000000  Default  13.0000  13.0000\n",
              "876         china   745.000000   745.000000  Default  12.0000  12.0000\n",
              "494         water   318.000000   318.000000  Default  11.0000  11.0000\n",
              "...           ...          ...          ...      ...      ...      ...\n",
              "78        prevent    80.109960   253.013609   Topic5  -5.2475   0.7897\n",
              "104            ha   111.169833  1083.613363   Topic5  -4.9198  -0.3373\n",
              "1129        wuhan    85.715194   392.599339   Topic5  -5.1799   0.4179\n",
              "5           covid    94.714297  2397.259901   Topic5  -5.0800  -1.2915\n",
              "0              19    92.219426  2382.914284   Topic5  -5.1067  -1.3122\n",
              "\n",
              "[220 rows x 6 columns], token_table=      Topic      Freq     Term\n",
              "term                          \n",
              "0         1  0.305508       19\n",
              "0         2  0.545970       19\n",
              "0         3  0.036090       19\n",
              "0         4  0.073439       19\n",
              "0         5  0.038608       19\n",
              "...     ...       ...      ...\n",
              "1129      3  0.583292    wuhan\n",
              "1129      4  0.028018    wuhan\n",
              "1129      5  0.219053    wuhan\n",
              "2166      1  0.939904  youtube\n",
              "2166      2  0.038363  youtube\n",
              "\n",
              "[446 rows x 3 columns], R=15, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 5, 4, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ju911l5P7cz"
      },
      "source": [
        "The dashboard will not be visible on GitHub, but [this](https://www.researchgate.net/profile/Tunazzina-Islam/publication/338491108/figure/fig3/AS:845535753818113@1578602841696/Visualization-using-pyLDAVis-Best-viewed-in-electronic-format-zoomed-in.ppm) is an example "
      ]
    }
  ]
}